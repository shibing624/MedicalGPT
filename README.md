[**ğŸ‡¨ğŸ‡³ä¸­æ–‡**](https://github.com/shibing624/MedicalGPT/blob/main/README.md) | [**ğŸŒEnglish**](https://github.com/shibing624/MedicalGPT/blob/main/README_EN.md) | [**ğŸ“–æ–‡æ¡£/Docs**](https://github.com/shibing624/MedicalGPT/wiki) | [**ğŸ¤–æ¨¡å‹/Models**](https://huggingface.co/shibing624) 

<div align="center">
  <a href="https://github.com/shibing624/MedicalGPT">
    <img src="https://github.com/shibing624/MedicalGPT/blob/main/docs/logo.png" height="100" alt="Logo">
  </a>
</div>

-----------------

# MedicalGPT: Training Medical GPT Model
[![HF Models](https://img.shields.io/badge/Hugging%20Face-shibing624-green)](https://huggingface.co/shibing624)
[![Github Stars](https://img.shields.io/github/stars/shibing624/MedicalGPT?color=yellow)](https://star-history.com/#shibing624/MedicalGPT&Timeline)
[![Contributions welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg)](CONTRIBUTING.md)
[![License Apache 2.0](https://img.shields.io/badge/license-Apache%202.0-blue.svg)](LICENSE)
[![python_version](https://img.shields.io/badge/Python-3.8%2B-green.svg)](requirements.txt)
[![GitHub issues](https://img.shields.io/github/issues/shibing624/MedicalGPT.svg)](https://github.com/shibing624/MedicalGPT/issues)
[![Wechat Group](http://vlog.sfyc.ltd/wechat_everyday/wxgroup_logo.png?imageView2/0/w/60/h/20)](#Contact)

## ğŸ“– Introduction

**MedicalGPT** training medical GPT model with ChatGPT training pipeline, implemantation of Pretraining, 
Supervised Finetuning, Reward Modeling and Reinforcement Learning.

**MedicalGPT** è®­ç»ƒåŒ»ç–—å¤§æ¨¡å‹ï¼Œå®ç°åŒ…æ‹¬äºŒæ¬¡é¢„è®­ç»ƒã€æœ‰ç›‘ç£å¾®è°ƒã€å¥–åŠ±å»ºæ¨¡ã€å¼ºåŒ–å­¦ä¹ è®­ç»ƒã€‚

<img src="https://github.com/shibing624/MedicalGPT/blob/main/docs/GPT_Training.jpg" width="860" />

åˆ†å››é˜¶æ®µè®­ç»ƒGPTæ¨¡å‹ï¼Œæ¥è‡ªAndrej Karpathyçš„æ¼”è®²PDF [State of GPT](https://karpathy.ai/stateofgpt.pdf)ï¼Œè§†é¢‘ [Video](https://build.microsoft.com/en-US/sessions/db3f4859-cd30-4445-a0cd-553c3304f8e2)

## ğŸ”¥ News
[2023/08/02] v1.3ç‰ˆæœ¬: æ–°å¢LLaMA, LLaMA2, Bloom, ChatGLM, ChatGLM2, Baichuanæ¨¡å‹çš„å¤šè½®å¯¹è¯å¾®è°ƒè®­ç»ƒï¼›æ–°å¢é¢†åŸŸè¯è¡¨æ‰©å……åŠŸèƒ½ï¼›æ–°å¢ä¸­æ–‡é¢„è®­ç»ƒæ•°æ®é›†å’Œä¸­æ–‡ShareGPTå¾®è°ƒè®­ç»ƒé›†ï¼Œè¯¦è§[Release-v1.3](https://github.com/shibing624/MedicalGPT/releases/tag/1.3.0)

[2023/07/13] v1.1ç‰ˆæœ¬: å‘å¸ƒä¸­æ–‡åŒ»ç–—LLaMA-13Bæ¨¡å‹[shibing624/ziya-llama-13b-medical-merged](https://huggingface.co/shibing624/ziya-llama-13b-medical-merged)ï¼ŒåŸºäºZiya-LLaMA-13B-v1æ¨¡å‹ï¼ŒSFTå¾®è°ƒäº†ä¸€ç‰ˆåŒ»ç–—æ¨¡å‹ï¼ŒåŒ»ç–—é—®ç­”æ•ˆæœæœ‰æå‡ï¼Œå‘å¸ƒå¾®è°ƒåçš„å®Œæ•´æ¨¡å‹æƒé‡ï¼Œè¯¦è§[Release-v1.1](https://github.com/shibing624/MedicalGPT/releases/tag/1.1)

[2023/06/15] v1.0ç‰ˆæœ¬: å‘å¸ƒä¸­æ–‡åŒ»ç–—LoRAæ¨¡å‹[shibing624/ziya-llama-13b-medical-lora](https://huggingface.co/shibing624/ziya-llama-13b-medical-lora)ï¼ŒåŸºäºZiya-LLaMA-13B-v1æ¨¡å‹ï¼ŒSFTå¾®è°ƒäº†ä¸€ç‰ˆåŒ»ç–—æ¨¡å‹ï¼ŒåŒ»ç–—é—®ç­”æ•ˆæœæœ‰æå‡ï¼Œå‘å¸ƒå¾®è°ƒåçš„LoRAæƒé‡ï¼Œè¯¦è§[Release-v1.0](https://github.com/shibing624/MedicalGPT/releases/tag/1.0.0)

[2023/06/05] v0.2ç‰ˆæœ¬: ä»¥åŒ»ç–—ä¸ºä¾‹ï¼Œè®­ç»ƒé¢†åŸŸå¤§æ¨¡å‹ï¼Œå®ç°äº†å››é˜¶æ®µè®­ç»ƒï¼šåŒ…æ‹¬äºŒæ¬¡é¢„è®­ç»ƒã€æœ‰ç›‘ç£å¾®è°ƒã€å¥–åŠ±å»ºæ¨¡ã€å¼ºåŒ–å­¦ä¹ è®­ç»ƒã€‚è¯¦è§[Release-v0.2](https://github.com/shibing624/MedicalGPT/releases/tag/0.2.0)


## ğŸ˜Š Feature
åŸºäºChatGPT Training Pipelineï¼Œæœ¬é¡¹ç›®å®ç°äº†é¢†åŸŸæ¨¡å‹--åŒ»ç–—æ¨¡å‹çš„å››é˜¶æ®µè®­ç»ƒï¼š

- ç¬¬ä¸€é˜¶æ®µï¼šPT(Continue PreTraining)å¢é‡é¢„è®­ç»ƒï¼Œåœ¨æµ·é‡é¢†åŸŸæ–‡æ¡£æ•°æ®ä¸ŠäºŒæ¬¡é¢„è®­ç»ƒGPTæ¨¡å‹ï¼Œä»¥æ³¨å…¥é¢†åŸŸçŸ¥è¯†
- ç¬¬äºŒé˜¶æ®µï¼šSFT(Supervised Fine-tuning)æœ‰ç›‘ç£å¾®è°ƒï¼Œæ„é€ æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†ï¼Œåœ¨é¢„è®­ç»ƒæ¨¡å‹åŸºç¡€ä¸ŠåšæŒ‡ä»¤ç²¾è°ƒï¼Œä»¥å¯¹é½æŒ‡ä»¤æ„å›¾
- ç¬¬ä¸‰é˜¶æ®µï¼šRM(Reward Model)å¥–åŠ±æ¨¡å‹å»ºæ¨¡ï¼Œæ„é€ äººç±»åå¥½æ’åºæ•°æ®é›†ï¼Œè®­ç»ƒå¥–åŠ±æ¨¡å‹ï¼Œç”¨æ¥å¯¹é½äººç±»åå¥½ï¼Œä¸»è¦æ˜¯"HHH"åŸåˆ™ï¼Œå…·ä½“æ˜¯"helpful, honest, harmless"
- ç¬¬å››é˜¶æ®µï¼šRL(Reinforcement Learning)åŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ (RLHF)ï¼Œç”¨å¥–åŠ±æ¨¡å‹æ¥è®­ç»ƒSFTæ¨¡å‹ï¼Œç”Ÿæˆæ¨¡å‹ä½¿ç”¨å¥–åŠ±æˆ–æƒ©ç½šæ¥æ›´æ–°å…¶ç­–ç•¥ï¼Œä»¥ä¾¿ç”Ÿæˆæ›´é«˜è´¨é‡ã€æ›´ç¬¦åˆäººç±»åå¥½çš„æ–‡æœ¬


### Release Models


| Model                                                                                                     | Base Model                                                                        | Introduction                                                                                                                           | 
|:----------------------------------------------------------------------------------------------------------|:----------------------------------------------------------------------------------|:---------------------------------------------------------------------------------------------------------------------------------------|
| [shibing624/ziya-llama-13b-medical-lora](https://huggingface.co/shibing624/ziya-llama-13b-medical-lora)   | [IDEA-CCNL/Ziya-LLaMA-13B-v1](https://huggingface.co/IDEA-CCNL/Ziya-LLaMA-13B-v1) | åœ¨240ä¸‡æ¡ä¸­è‹±æ–‡åŒ»ç–—æ•°æ®é›†[shibing624/medical](https://huggingface.co/datasets/shibing624/medical)ä¸ŠSFTå¾®è°ƒäº†ä¸€ç‰ˆZiya-LLaMA-13Bæ¨¡å‹ï¼ŒåŒ»ç–—é—®ç­”æ•ˆæœæœ‰æå‡ï¼Œå‘å¸ƒå¾®è°ƒåçš„LoRAæƒé‡ |
| [shibing624/ziya-llama-13b-medical-merged](https://huggingface.co/shibing624/ziya-llama-13b-medical-merged) | [IDEA-CCNL/Ziya-LLaMA-13B-v1](https://huggingface.co/IDEA-CCNL/Ziya-LLaMA-13B-v1) | åœ¨240ä¸‡æ¡ä¸­è‹±æ–‡åŒ»ç–—æ•°æ®é›†[shibing624/medical](https://huggingface.co/datasets/shibing624/medical)ä¸ŠSFTå¾®è°ƒäº†ä¸€ç‰ˆZiya-LLaMA-13Bæ¨¡å‹ï¼ŒåŒ»ç–—é—®ç­”æ•ˆæœæœ‰æå‡ï¼Œå‘å¸ƒå¾®è°ƒåçš„å®Œæ•´æ¨¡å‹æƒé‡ |


## â–¶ï¸ Demo


æˆ‘ä»¬æä¾›äº†ä¸€ä¸ªç®€æ´çš„åŸºäºgradioçš„äº¤äº’å¼webç•Œé¢ï¼Œå¯åŠ¨æœåŠ¡åï¼Œå¯é€šè¿‡æµè§ˆå™¨è®¿é—®ï¼Œè¾“å…¥é—®é¢˜ï¼Œæ¨¡å‹ä¼šè¿”å›ç­”æ¡ˆã€‚

å¯åŠ¨æœåŠ¡ï¼Œå‘½ä»¤å¦‚ä¸‹ï¼š
```shell
CUDA_VISIBLE_DEVICES=0 python gradio_demo.py --model_type base_model_type --base_model path_to_llama_hf_dir --lora_model path_to_lora_dir
```

å‚æ•°è¯´æ˜ï¼š

- `--model_type {base_model_type}`ï¼šé¢„è®­ç»ƒæ¨¡å‹ç±»å‹ï¼Œå¦‚llamaã€bloomã€chatglmç­‰
- `--base_model {base_model}`ï¼šå­˜æ”¾HFæ ¼å¼çš„LLaMAæ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶çš„ç›®å½•ï¼Œä¹Ÿå¯ä½¿ç”¨HF Model Hubæ¨¡å‹è°ƒç”¨åç§°
- `--lora_model {lora_model}`ï¼šLoRAæ–‡ä»¶æ‰€åœ¨ç›®å½•ï¼Œä¹Ÿå¯ä½¿ç”¨HF Model Hubæ¨¡å‹è°ƒç”¨åç§°ã€‚è‹¥loraæƒé‡å·²ç»åˆå¹¶åˆ°é¢„è®­ç»ƒæ¨¡å‹ï¼Œåˆ™åˆ é™¤--lora_modelå‚æ•°
- `--tokenizer_path {tokenizer_path}`ï¼šå­˜æ”¾å¯¹åº”tokenizerçš„ç›®å½•ã€‚è‹¥ä¸æä¾›æ­¤å‚æ•°ï¼Œåˆ™å…¶é»˜è®¤å€¼ä¸--base_modelç›¸åŒ
- `--only_cpu`: ä»…ä½¿ç”¨CPUè¿›è¡Œæ¨ç†
- `--gpus {gpu_ids}`: æŒ‡å®šä½¿ç”¨çš„GPUè®¾å¤‡ç¼–å·ï¼Œé»˜è®¤ä¸º0ã€‚å¦‚ä½¿ç”¨å¤šå¼ GPUï¼Œä»¥é€—å·åˆ†éš”ï¼Œå¦‚0,1,2
- `--resize_emb`ï¼šæ˜¯å¦è°ƒæ•´embeddingå¤§å°ï¼Œè‹¥ä¸è°ƒæ•´ï¼Œåˆ™ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹çš„embeddingå¤§å°ï¼Œé»˜è®¤ä¸è°ƒæ•´


## ğŸ’¾ Install
#### Updating the requirements
From time to time, the `requirements.txt` changes. To update, use this command:

```markdown
git clone https://github.com/shibing624/MedicalGPT
conda activate gpt
cd MedicalGPT
pip install -r requirements.txt --upgrade
```

## ğŸš€ Training Pipeline

Training Stage:

| Stage                           | Introduction |  Python script                                                                                                           | Shell script                                                                        |                      
|:--------------------------------|:-------------|:------------------------------------------------------------------------------------------------------------------------|:------------------------------------------------------------------------------------|
| Stage 1: Continue Pretraining   | å¢é‡é¢„è®­ç»ƒ        |          [pretraining.py](https://github.com/shibing624/MedicalGPT/blob/main/pretraining.py)                     | [run_pt.sh](https://github.com/shibing624/MedicalGPT/blob/main/run_pt.sh)   | 
| Stage 2: Supervised Fine-tuning | æœ‰ç›‘ç£å¾®è°ƒ        | [supervised_finetuning.py](https://github.com/shibing624/MedicalGPT/blob/main/supervised_finetuning.py) | [run_sft.sh](https://github.com/shibing624/MedicalGPT/blob/main/run_sft.sh) | 
| Stage 3: Reward Modeling        | å¥–åŠ±æ¨¡å‹å»ºæ¨¡       | [reward_modeling.py](https://github.com/shibing624/MedicalGPT/blob/main/reward_modeling.py)             | [run_rm.sh](https://github.com/shibing624/MedicalGPT/blob/main/run_rm.sh)   | 
| Stage 4: Reinforcement Learning | å¼ºåŒ–å­¦ä¹          |  [rl_training.py](https://github.com/shibing624/MedicalGPT/blob/main/rl_training.py)                     | [run_rl.sh](https://github.com/shibing624/MedicalGPT/blob/main/run_rl.sh)   | 

- æä¾›å®Œæ•´å››é˜¶æ®µä¸²èµ·æ¥è®­ç»ƒçš„pipelineï¼š[run_training_pipeline.ipynb](https://github.com/shibing624/MedicalGPT/blob/main/run_training_pipeline.ipynb) ï¼Œå…¶å¯¹åº”çš„colabï¼š [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/shibing624/MedicalGPT/blob/main/run_training_pipeline.ipynb) ï¼Œè¿è¡Œå®Œå¤§æ¦‚éœ€è¦15åˆ†é’Ÿï¼Œæˆ‘è¿è¡ŒæˆåŠŸåçš„å‰¯æœ¬colabï¼š[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1RGkbev8D85gR33HJYxqNdnEThODvGUsS?usp=sharing)
- [è®­ç»ƒå‚æ•°è¯´æ˜wiki](https://github.com/shibing624/MedicalGPT/wiki/%E8%AE%AD%E7%BB%83%E5%8F%82%E6%95%B0%E8%AF%B4%E6%98%8E)
- [æ•°æ®é›†wiki](https://github.com/shibing624/MedicalGPT/wiki/%E6%95%B0%E6%8D%AE%E9%9B%86)
- [æ‰©å……è¯è¡¨wiki](https://github.com/shibing624/MedicalGPT/wiki/%E6%89%A9%E5%85%85%E4%B8%AD%E6%96%87%E8%AF%8D%E8%A1%A8)
- [FAQ](https://github.com/shibing624/MedicalGPT/wiki/FAQ)
#### Supported Models
The following models are tested:

bloom:
- [bigscience/bloomz-560m](https://huggingface.co/bigscience/bloomz-560m)
- [bigscience/bloomz-1b7](https://huggingface.co/bigscience/bloomz-1b7)
- [bigscience/bloomz-7b1](https://huggingface.co/bigscience/bloomz-7b1)

llama:
- [shibing624/chinese-alpaca-plus-7b-hf](https://huggingface.co/shibing624/chinese-alpaca-plus-7b-hf)
- [shibing624/chinese-alpaca-plus-13b-hf](https://huggingface.co/shibing624/chinese-alpaca-plus-13b-hf)
- [minlik/chinese-llama-plus-7b-merged](https://huggingface.co/minlik/chinese-llama-plus-7b-merged)
- [shibing624/chinese-llama-plus-13b-hf](https://huggingface.co/shibing624/chinese-llama-plus-13b-hf)
- [decapoda-research/llama-7b-hf](https://huggingface.co/decapoda-research/llama-7b-hf)
- [IDEA-CCNL/Ziya-LLaMA-13B-v1](https://huggingface.co/IDEA-CCNL/Ziya-LLaMA-13B-v1)

llama2:
- [daryl149/llama-2-7b-chat-hf](https://huggingface.co/daryl149/llama-2-7b-chat-hf)
- [meta-llama/Llama-2-7b-chat-hf](https://huggingface.co/meta-llama/Llama-2-7b-chat-hf)

chatglm:
- [THUDM/chatglm-6b](https://huggingface.co/THUDM/chatglm-6b)
- [THUDM/chatglm2-6b](https://huggingface.co/THUDM/chatglm2-6b)

baichuan:
- [baichuan-inc/baichuan-7B](https://huggingface.co/baichuan-inc/baichuan-7B)
- [baichuan-inc/Baichuan-13B-Base](https://huggingface.co/baichuan-inc/Baichuan-13B-Base)
- [baichuan-inc/Baichuan-13B-Chat](https://huggingface.co/baichuan-inc/Baichuan-13B-Chat)

## ğŸ’» Inference 
è®­ç»ƒå®Œæˆåï¼Œç°åœ¨æˆ‘ä»¬åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹ï¼ŒéªŒè¯æ¨¡å‹ç”Ÿæˆæ–‡æœ¬çš„æ•ˆæœã€‚

```shell
CUDA_VISIBLE_DEVICES=0 python inference.py \
    --model_type base_model_type \
    --base_model path_to_model_hf_dir \
    --tokenizer_path path_to_model_hf_dir \
    --lora_model path_to_lora \
    --interactive
```

å‚æ•°è¯´æ˜ï¼š

- `--model_type {base_model_type}`ï¼šé¢„è®­ç»ƒæ¨¡å‹ç±»å‹ï¼Œå¦‚llamaã€bloomã€chatglmç­‰
- `--base_model {base_model}`ï¼šå­˜æ”¾HFæ ¼å¼çš„LLaMAæ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶çš„ç›®å½•
- `--tokenizer_path {base_model}`ï¼šå­˜æ”¾HFæ ¼å¼çš„LLaMAæ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶çš„ç›®å½•
- `--lora_model {lora_model}`ï¼šLoRAè§£å‹åæ–‡ä»¶æ‰€åœ¨ç›®å½•ï¼Œä¹Ÿå¯ä½¿ç”¨HF Model Hubæ¨¡å‹è°ƒç”¨åç§°ã€‚å¦‚æœå·²ç»åˆå¹¶äº†LoRAæƒé‡åˆ°é¢„è®­ç»ƒæ¨¡å‹ï¼Œåˆ™å¯ä»¥ä¸æä¾›æ­¤å‚æ•°
- `--tokenizer_path {tokenizer_path}`ï¼šå­˜æ”¾å¯¹åº”tokenizerçš„ç›®å½•ã€‚è‹¥ä¸æä¾›æ­¤å‚æ•°ï¼Œåˆ™å…¶é»˜è®¤å€¼ä¸--base_modelç›¸åŒ
- `--template_name`ï¼šæ¨¡æ¿åç§°ï¼Œå¦‚`vicuna`ã€`alpaca`ç­‰ã€‚è‹¥ä¸æä¾›æ­¤å‚æ•°ï¼Œåˆ™å…¶é»˜è®¤å€¼æ˜¯alpaca
- `--interactive`ï¼šä»¥äº¤äº’æ–¹å¼å¯åŠ¨å¤šè½®é—®ç­”ï¼Œä½¿ç”¨æµå¼æ¨ç†
- `--data_file {file_name}`ï¼šéäº¤äº’æ–¹å¼å¯åŠ¨ä¸‹ï¼ŒæŒ‰è¡Œè¯»å–file_nameä¸­çš„çš„å†…å®¹è¿›è¡Œé¢„æµ‹
- `--predictions_file {file_name}`ï¼šéäº¤äº’å¼æ–¹å¼ä¸‹ï¼Œå°†é¢„æµ‹çš„ç»“æœä»¥jsonæ ¼å¼å†™å…¥file_name
- `--resize_emb`ï¼šæ˜¯å¦è°ƒæ•´embeddingå¤§å°ï¼Œè‹¥ä¸è°ƒæ•´ï¼Œåˆ™ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹çš„embeddingå¤§å°ï¼Œé»˜è®¤ä¸è°ƒæ•´
- `--only_cpu`ï¼šä»…ä½¿ç”¨CPUè¿›è¡Œæ¨ç†
- `--gpus {gpu_ids}`ï¼šæŒ‡å®šä½¿ç”¨çš„GPUè®¾å¤‡ç¼–å·ï¼Œé»˜è®¤ä¸º0ã€‚å¦‚ä½¿ç”¨å¤šå¼ GPUï¼Œä»¥é€—å·åˆ†éš”ï¼Œå¦‚0,1,2


#### Inference Examples
[shibing624/ziya-llama-13b-medical-merged](https://huggingface.co/shibing624/ziya-llama-13b-medical-merged) inference examples:

<details><summary>Model output case</summary>

| Human                                                                              | Assitant                                                                                                                                                                                                                                                                                                                                                                                            |
|------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| å°å­©å‘çƒ§æ€ä¹ˆåŠ                                                                            | å®å®çš„æŠµæŠ—åŠ›æ˜¯æ¯”è¾ƒå·®çš„ï¼Œæ‰€ä»¥å¾ˆå®¹æ˜“å°±ä¼šå‡ºç°æ„Ÿå†’æˆ–è€…å…¶ä»–ç–¾ç—…ã€‚å¦‚æœå®å®åœ¨å¹³æ—¶æ²¡æœ‰æ³¨æ„ä¿æš–ï¼Œé‚£ä¹ˆä¹Ÿå¯èƒ½å¯¼è‡´èº«ä½“å—å‡‰è€Œå¼•èµ·äº†æ„Ÿå†’ç­‰ç—‡çŠ¶ï¼Œè¿™æ ·ä¸ä»…å¯¹äºå¥åº·é€ æˆå½±å“ï¼Œè¿˜å¯èƒ½è®©å®å®å‡ºç°é«˜çƒ­çš„æƒ…å†µã€‚å› æ­¤å½“å®¶é•¿ä»¬å‘ç°è‡ªå·±çš„å®å®å‡ºç°äº†é«˜çƒ­çš„é—®é¢˜ä¹‹åä¸€å®šè¦åŠæ—©è¿›è¡Œæ²»ç–—å’ŒæŠ¤ç†æ‰å¥½ã€‚<br/>1ã€é¦–å…ˆæˆ‘ä»¬åº”è¯¥ç»™å®å®æœç”¨é€€çƒ§è¯ç‰©æ¥å¸®åŠ©é™æ¸©ï¼Œä½†æ˜¯åƒä¸‡ä¸è¦ç›²ç›®ä½¿ç”¨é€€çƒ§è¯ç‰©ï¼Œå¦åˆ™åªä¼šåŠ é‡å®å®çš„ç—…æƒ…ï¼Œæœ€å¥½å¸¦ç€å®å®åˆ°åŒ»é™¢å»æ£€æŸ¥æ¸…æ¥šå…·ä½“åŸå› ä¹‹åå†é’ˆå¯¹æ€§åœ°é‡‡å–æªæ–½å¤„ç†ã€‚<br/>2ã€å¦å¤–å¤§äººä»¬ä¹Ÿéœ€è¦åšå¥½é¢„é˜²å·¥ä½œï¼Œå°¤å…¶æ˜¯å¤©æ°”å˜åŒ–çš„æ—¶å€™æ›´åº”è¯¥å¤šå…³å¿ƒä¸‹å®å®çš„èº«ä½“çŠ¶æ€ï¼Œé¿å…å®å®å—å¯’å—å‡‰ä»è€Œè¯±å‘å„ç§ç–¾ç—…ï¼ŒåŒæ—¶ä¹Ÿè¦å°½é‡å‡å°‘å®å®æ¥è§¦ç»†èŒç—…æ¯’çš„æœºä¼šï¼Œå¢å¼ºå®å®çš„å…ç–«åŠ›ã€‚<br/>3ã€é™¤äº†ä¸Šé¢ä¸¤ç‚¹ä¹‹å¤–ï¼Œå¤§äººä»¬è¿˜å¯ä»¥é€šè¿‡æŒ‰æ‘©æ¨æ‹¿ç©´ä½çš„æ–¹å¼æ¥ç¼“è§£å®å®çš„ç—…ç—›ï¼Œä¿ƒè¿›è¡€æ¶²å¾ªç¯ï¼Œæå‡æ–°é™ˆä»£è°¢é€Ÿåº¦ï¼Œè¾¾åˆ°å¿«é€Ÿæ¶ˆç‚æ­¢ç–¼çš„æ•ˆæœ         |
| ä¸€å²å®å®å‘çƒ§èƒ½åƒå•¥è¯ï¼Ÿ                                                                        | å­©å­çš„èº«ä½“æ˜¯å¾ˆè„†å¼±çš„ï¼Œå¦‚æœä¸æ³¨æ„ä¿æŠ¤å¥½è‡ªå·±å°±ä¼šå‡ºç°å„ç§ç–¾ç—…ã€‚æœ‰äº›å®¶é•¿åœ¨çœ‹åˆ°å­©å­ç”Ÿç—…åéƒ½éå¸¸ç€æ€¥ï¼Œæƒ³è¦ç«‹åˆ»ç»™ä»–ä»¬ç”¨è¯æ²»ç–—ï¼Œä½†å…¶å®å¹¶æ²¡æœ‰é‚£ä¹ˆç®€å•ï¼Œå› ä¸ºæ¯ä¸ªäººå¯¹äºè¯ç‰©çš„æ•æ„Ÿåº¦å’Œè€å—æ€§éƒ½æ˜¯ä¸åŒçš„ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦æ ¹æ®å…·ä½“æƒ…å†µæ¥é€‰æ‹©åˆé€‚çš„æ–¹æ³•è¿›è¡Œæ²»ç–—æ‰å¯ä»¥è¾¾åˆ°æœ€ä½³æ•ˆæœã€‚<br/>1ã€é¦–å…ˆå¤§å¤šæ•°å°å„¿é€€çƒ­è¯ä¸­å«æœ‰è§£çƒ­é•‡ç—›æˆåˆ†é˜¿å¸åŒ¹æ—æˆ–å¸ƒæ´›èŠ¬ç­‰ï¼Œè¿™ç±»è¯å“è™½ç„¶å‰¯ä½œç”¨è¾ƒå°‘ï¼Œä½†ä¹Ÿå­˜åœ¨è¿‡é‡ä½¿ç”¨å¼•èµ·èƒƒè‚ é“æŸä¼¤ç”šè‡³æ¶ˆåŒ–é“æºƒç–¡å‡ºè¡€çš„é£é™©ï¼›<br/>2ã€è¿˜æœ‰éƒ¨åˆ†å°å„¿é€€çƒ­è¯ä¸­å«æœ‰æ‰‘å°”æ•ç­‰æŠ—ç»„èƒºè¯ï¼Œå®ƒä»¬æœ¬èº«å±äºå¤„æ–¹è¯ï¼Œåº”è¯¥ä¸¥æ ¼æŒ‰ç…§åŒ»å˜±æœç”¨ï¼Œåˆ‡å‹¿æ“…è‡ªåŠ å‡å‰‚é‡æˆ–è€…å»¶é•¿ç”¨è¯æ—¶é—´;<br/>3ã€æ­¤å¤–ï¼ŒæŸäº›å°å„¿é€€çƒ­è¯ä¸­å«æœ‰ç»´ç”Ÿç´ CåŠè‘¡è„ç³–é…¸é’™ç­‰è¥å…»è¡¥å……å‰‚ï¼Œåªæœ‰å½“æ‚£å„¿ä¼´éšè„±æ°´ç—‡çŠ¶ï¼ˆå¦‚å£æ¸´ã€å°¿è‰²æ·±ï¼‰æ—¶æ‰è€ƒè™‘æ·»åŠ ï¼Œå¦åˆ™å®¹æ˜“é€ æˆç”µè§£è´¨ç´Šä¹±ã€‚                                                    |
| è‚›é—¨ç—…å˜å¯èƒ½æ˜¯ä»€ä¹ˆç–¾ç—…çš„ç—‡çŠ¶                                                                     | ç—”ç–®ã€ç›´è‚ æ¯è‚‰ç­‰ã€‚                                                                                                                                                                                                                                                                                                                                                                                           |
| åŒ»ç”Ÿï¼Œæ‚¨å¥½ç™½å¸¦å¢å¤šæ³›é»„æ€ä¹ˆå›äº‹ï¼Ÿ                                                                   | ä½ è¿™ç§æƒ…å†µè€ƒè™‘å¯èƒ½ä¼šæ˜¯é˜´é“ç‚ç—‡å¼•èµ·çš„å»ºè®®å¹³æ—¶ç•™æ„å«ç”Ÿæ¸…æ´ï¼Œå‹¤æ¢æ´—è¡£ç‰©å†…è£¤ï¼Œå¿…è¦æ—¶å»æ­£è§„å…¬ç«‹åŒ»é™¢å¦‡ç§‘å¤è¯Šåšåˆ†æ³Œç‰©å¸¸è§„ç­‰ç›¸å…³æ£€æŸ¥æ˜ç¡®ç—…å› åå¯¹ç—‡æ²»ç–—ï¼Œä¸åŒåŸå› æ‰€è‡´çš„ç–¾ç—…åœ¨ä¸´åºŠè¡¨ç°ä¸Šä¹Ÿå­˜åœ¨å·®å¼‚æ€§ï¼Œå¦‚æœæ‚£è€…å‡ºç°äº†ç±»ä¼¼äºçš„ç—‡çŠ¶åº”å½“åŠæ—©åˆ°ä¸“ä¸šã€æƒå¨çš„åŒ»é™¢è¿›è¡Œè¯¦ç»†çš„æ£€éªŒå’Œæ•‘æ²»                                                                                                                                                                                                                                                                  |
| è¯æµåæœ‰å·§å…‹åŠ›ç™½å¸¦æ˜¯æ²¡æµå¹²å‡€å—                                                                    | åœ¨æ—¥å¸¸ç”Ÿæ´»ä¸­ï¼Œæˆ‘ä»¬è¦æˆ–å¤šæˆ–å°‘äº†è§£ä¸€äº›å¸¸è§ç–¾ç—…çš„ç›¸å…³çŸ¥è¯†ï¼Œä¸ä»…èƒ½èµ·åˆ°å¢åŠ çŸ¥è¯†æ°´å¹³çš„ä½œç”¨ï¼Œæ›´èƒ½è®©è‡ªå·±æ›´å¥½åœ°é¢„é˜²æ­¤ç±»ç–¾ç—…çš„äº§ç”Ÿã€‚å¾ˆå¤šå¥³æ€§éƒ½ä¼šå‡ºç°æœˆç»ç´Šä¹±ã€è…¹ç—›ç­‰ç—‡çŠ¶ï¼Œè¿™æ—¶å€™å°±éœ€è¦è€ƒè™‘å¦‡ç§‘ç‚ç—‡å¯èƒ½ï¼Œæ¯”å¦‚è¯´å®«é¢ˆç³œçƒ‚å’Œç›†è…”ç§¯æ¶²ã€‚é‚£ä¹ˆä¸‹é¢å°ç¼–æ¥ç»™å¤§å®¶ä»‹ç»ä¸€ç§æƒ…å†µï¼šè¯ç‰©æµäº§åç™½å¸¦å‘ˆå·§å…‹åŠ›è‰²æ€ä¹ˆå›äº‹ï¼Ÿ<br/>1ã€é¦–å…ˆï¼Œå¯¹äºè¯ç‰©æµäº§ä¹‹åå‘ç°é˜´é“åˆ†æ³Œç‰©å¼‚å¸¸ï¼Œåº”è¯¥åŠæ—¶å»åŒ»é™¢åšæ£€æŸ¥ç¡®è¯Šå…·ä½“åŸå› ï¼Œç„¶åå†æ ¹æ®ç»“æœè¿›è¡Œæ²»ç–—è°ƒç†ã€‚<br/>2ã€å…¶æ¬¡ï¼Œç”±äºæ¯ä¸ªäººèº«ä½“ç´ è´¨ä»¥åŠæ‚£ç—…ç¨‹åº¦å­˜åœ¨å·®åˆ«ï¼Œæ‰€ä»¥é‡‡å–çš„æªæ–½ä¹Ÿä¸å°½ç›¸åŒï¼Œä½†æ— è®ºé€‰æ‹©å“ªç§æ–¹å¼å¤„ç†ï¼Œéƒ½å¿…é¡»ä¸¥æ ¼æŒ‰ç…§è§„å®šå‰‚é‡æœç”¨ï¼Œå¹¶ä¸”æ³¨æ„è§‚å¯Ÿå‰¯ä½œç”¨åæ˜ æƒ…å†µï¼Œè‹¥å‡ºç°æ˜æ˜¾ä¸é€‚æ„Ÿè§‰ï¼Œåˆ™åº”ç«‹å³åœæ­¢ä½¿ç”¨ã€‚<br/>3ã€æœ€åï¼Œå»ºè®®ä½ ä¿æŒå¤–é˜´æ¸…æ´å«ç”Ÿï¼Œå‹¤æ¢å†…è£¤ï¼Œé¿å…åƒè¾›è¾£åˆºæ¿€é£Ÿå“ï¼Œè€Œä¸”è¿˜è¦ç¦å¿Œæˆ¿äº‹ï¼Œå¦åˆ™å®¹æ˜“å¼•èµ·äº¤å‰æ„ŸæŸ“å½±å“æ¢å¤å¥åº·ã€‚                                |
| ç»´èƒºé…¯ç»´Eä¹³è†èƒ½æ²»ç†ä»€ä¹ˆç–¾ç—…                                                                     | çš®è‚¤æ·€ç²‰æ ·å˜æ€§ï¼›è„‚æº¢æ€§è§’åŒ–ç—‡                                                                                                                                                                                                                                                                                                                                                                                      |
| ç—¤ç–®æ˜¯ä»€ä¹ˆåŸå› å¯¼è‡´çš„?                                                                        | ç—¤ç–®ï¼Œåˆç§°é’æ˜¥ç—˜ã€ç²‰åˆºã€‚å®ƒä¸»è¦å‘ç”Ÿåœ¨é¢éƒ¨å’Œèƒ¸èƒŒéƒ¨ä½ï¼Œè¡¨ç°ä¸ºé»‘å¤´ç²‰åˆºã€ç™½å¤´ç²‰åˆºã€ä¸˜ç–¹ã€è„“ç–±ã€ç»“èŠ‚ç­‰å¤šç§å½¢å¼ã€‚å…¶ä¸­ä»¥é»‘å¤´ç²‰åˆºæœ€å¸¸è§ï¼Œçº¦å å…¨èº«çš®è‚¤ç—…æ‚£è€…çš„70%å·¦å³ã€‚é‚£ä¹ˆï¼Œç—¤ç–®æ˜¯ä»€ä¹ˆåŸå› å¼•èµ·çš„å‘¢ï¼Ÿä¸‹é¢å°±ç»™å¤§å®¶ä»‹ç»ä¸€äº›ç›¸å…³å†…å®¹ã€‚<br/>1ã€é›„æ€§æ¿€ç´ åˆ†æ³Œè¿‡æ—ºï¼šç”·å¥³éƒ½ä¼šé•¿ç—˜ç—˜ï¼Œä½†æ˜¯å¥³å­©å­æ¯”è¾ƒå–œæ¬¢ç”¨åŒ–å¦†å“æ¥æ©ç›–è„¸ä¸Šçš„é—®é¢˜ï¼Œè€Œä¸”å¾ˆå¤šäººä¸çŸ¥é“è¿™æ ·åšåè€ŒåŠ é‡äº†è‡ªå·±çš„æ¯›å›Šç‚ç—‡çŠ¶ï¼Œæ‰€ä»¥è¯´å¹³æ—¶åº”è¯¥å°‘ä½¿ç”¨å«æœ‰é›Œæ¿€ç´ ç±»çš„äº§å“ã€‚<br/>2ã€é¥®é£Ÿä¹ æƒ¯å·®ï¼šç»å¸¸åƒè¾›è¾£æ²¹è…»çš„ä¸œè¥¿æˆ–è€…ç”œé£Ÿä¹Ÿå¯èƒ½é€ æˆä½“å†…æ¯’ç´ å †ç§¯ï¼Œä»è€Œè¯±å‘ç—¤ç–®ã€‚<br/>3ã€å‹åŠ›å¤ªå¤§ï¼šå¦‚æœä½ æ€»æ˜¯å¤„äºç´§å¼ ç„¦è™‘çš„æƒ…ç»ªä¹‹ä¸­ï¼ŒåŒæ—¶è¿˜æ²¡æœ‰åŠæ—¶è°ƒæ•´å¥½å¿ƒæ€ï¼Œé‚£ä¹ˆå¾ˆå®¹æ˜“å‡ºç°å†…åˆ†æ³Œå¤±è°ƒçš„æƒ…å†µï¼Œè¿›è€Œå½±å“åˆ°è‚Œè‚¤å¥åº·ã€‚<br/>4ã€ç¡çœ è´¨é‡å·®ï¼šç†¬å¤œå¯¹æˆ‘ä»¬çš„èº«ä½“ä¼¤å®³éå¸¸ä¸¥é‡ï¼Œå°¤å…¶æ˜¯å¯¹äºå¹´è½»äººç¾¤æ›´ç”šï¼Œä»–ä»¬éœ€è¦ä¿è¯å……è¶³çš„ç¡çœ æ‰è¡Œï¼Œå¦åˆ™å¾ˆå®¹æ˜“è®©è‚Œè‚¤å˜å¾—æš—æ²‰æ— å…‰æ³½ã€‚                  |
| è„¸ä¸Šé•¿é’æ˜¥ç—˜æ€ä¹ˆåŠ,èƒ½åƒå•¥è¯,éœ€è¦æ³¨æ„å•¥                                                               | ä½ å¥½ï¼Œæ ¹æ®æ‚¨çš„æè¿°è€ƒè™‘æ˜¯ç—¤ç–®ã€‚å»ºè®®å¤–ç”¨ç»´èƒºé…¯ä¹³è†æˆ–è€…é˜¿è¾¾å¸•æ—å‡èƒ¶è¿›è¡Œæ²»ç–—çœ‹çœ‹ï¼Œå¹³æ—¶ç¦å¿Œè¾›è¾£å’Œåˆºæ¿€æ€§é£Ÿç‰©ï¼Œå¦‚æµ·é²œã€ç‹—è‚‰ã€ç¾Šè‚‰ç­‰â€œå‘â€åŠ¨å“ï¼Œä»¥åŠè‘±è’œéŸ­å§œç­‰åˆºæ¿€æ€§è°ƒæ–™ã€‚å¤šå–æ°´ï¼Œå°‘åƒæ²¹è…»é«˜çƒ­é‡é£Ÿç‰©ã€‚                                                                                                                                                                                                                                                                                                     |
| ç”±äºè¾“ç²¾ç®¡å µå¡ä¼šä¸ä¼šå¯¼è‡´ç”·æ€§ä¸è‚²ï¼Ÿï¼ŒåŒ»ç”Ÿæ‚¨å¥½ï¼Œæˆ‘åŒäº‹è¿™å‡ å¤©ä¸å¼€å¿ƒï¼Œæˆ‘é—®å¥¹æ€ä¹ˆäº†ï¼Œå¥¹è¯´å¥¹è€å…¬è¾“ç²¾ç®¡å µå¡ï¼Œæ‰€ä»¥ä¸€ç›´æ²¡å­©å­ï¼Œä¸æ˜¯ä¸æƒ³è¦ï¼Œè¯·é—®è¾“ç²¾ç®¡å µå¡ä¼šä¸ä¼šå¯¼è‡´ç”·æ€§ä¸è‚²ï¼Ÿ | ä½ å¥½ï¼æ ¹æ®ä½ çš„å™è¿°åŠç—‡çŠ¶æ¨æµ‹ï¼šå¦‚æœæœ‰è¾“ç²¾ç®¡é˜»å¡æˆ–è€…ç‹­çª„ç­‰æƒ…å†µéƒ½å¯èƒ½ä¼šå¼•æ¥æ— æ³•æ’å‡ºæ¥ç²¾æ¶²è€Œå½±å“æ€€ä¸Šã€‚å»ºè®®åˆ°æ­£è§„ä¸“ä¸šçš„å¿«å­•åŒ»é™¢å®æ–½è¿›è¡Œå’¨è¯¢å’Œæ²»ç–—ä¸ºå®œã€‚å¯¹äºè¾“ç²¾ç®¡æ‚£è€…æ¥è¯´ï¼ŒåŠæ—¶æ•‘æ²»æ˜¯å¯ä»¥å‡ä½ç—…å‘ï¼Œå¦‚æœä¸åŠæ—¶æ•‘æ²»ä¼šå½±å“åˆ°å—å­•æƒ…å†µã€‚å› æ­¤æ‚£è€…è¦åŠæ—¶è¯ç‰©æ•‘æ²»ï¼Œå¹¶ä¸”æ—¥å¸¸ç”Ÿæ´»ä¸­è¦å¤šçœ‹é‡è‡ªèº«æŠ¤ç†                                                                                                                                                                                                                                                          |
| å¿ƒè‚Œæ¢—å¡èƒ½æ²»ç–—å—ï¼Ÿ                                                                          | å¿ƒè„ç—…æ˜¯ä¸€ç§å±å®³æ€§æå¤§çš„ç–¾ç—…ï¼Œæˆ‘ä»¬è¦å¯¹å®ƒæœ‰è¶³å¤Ÿå¤šçš„äº†è§£ã€‚åœ¨ç”Ÿæ´»ä¸­å¾ˆå¤šäººéƒ½ä¼šæ‚£ä¸Šè¿™ä¸ªç–¾ç—…ï¼Œè€Œä¸”è¿˜ä¸çŸ¥é“æ€ä¹ˆå»é¢„é˜²å’ŒæŠ¤ç†ï¼Œæ‰€ä»¥å°±å¯¼è‡´è‡ªå·±çš„èº«ä½“è¶Šæ¥è¶Šå·®ï¼Œé‚£ä¹ˆä¸‹é¢å°ç¼–ç»™ä½ ä»‹ç»å‡ ç‚¹å…³äºå¿ƒè„ç—…çš„å¸¸è¯†å§ï¼<br/>1ã€å† çŠ¶åŠ¨è„‰ç²¥æ ·ç¡¬åŒ–æ€§å¿ƒè„ç—…ï¼šåˆç§°ä¸ºå† å¿ƒç—…æˆ–ç¼ºè¡€å‹å¿ƒè„ç—…ï¼ˆIHDï¼‰,æ˜¯ä¸–ç•Œå„åœ°æœ€é‡è¦çš„æ­»äº¡åŸå› ä¹‹ä¸€ã€‚<br/>2ã€é£æ¹¿çƒ­ï¼šä¸»è¦ä¾µçŠ¯å¿ƒè„ç“£è†œï¼Œå¯å¼•èµ·äºŒå°–ç“£ç‹­çª„åŠå…¶ä»–ç±»å‹çš„å¿ƒè„ç“£è†œç—…å˜ï¼›<br/>3ã€å…ˆå¤©æ€§å¿ƒè„ç—…ï¼šåŒ…æ‹¬æˆ¿é—´éš”ç¼ºæŸã€å®¤é—´éš”ç¼ºæŸç­‰ï¼›<br/>4ã€é«˜è„‚è›‹ç™½è¡€ç—‡ï¼šç”±äºèƒ†å›ºé†‡ä¸ä½å¯†åº¦è„‚è›‹ç™½å‡é«˜ï¼Œä½¿å¾—åŠ¨è„‰å£å¢åšï¼Œç®¡è…”ç¼©å°ï¼Œæ˜“å½¢æˆæ–‘å—å¹¶è„±è½é€ æˆæ€¥æ€§æ “å¡ï¼›<br/>5ã€è‚¥èƒ–ï¼šè¿‡é‡æ‘„å…¥é£Ÿç‰©ï¼Œç‰¹åˆ«æ˜¯å«ç³–é¥®æ–™ï¼ŒåŠ é€Ÿè„‚è‚ªå †ç§¯ï¼Œä¿ƒè¿›åŠ¨è„‰ç²¥æ ·ç¡¬åŒ–å‘å±•ï¼›<br/>6ã€å¸çƒŸï¼šå°¼å¤ä¸åˆºæ¿€äº¤æ„Ÿç¥ç»å…´å¥‹ï¼Œä½¿å¤–å‘¨é˜»åŠ›å¢å¼ºï¼Œæ”¶ç¼©å‹å‡é«˜ï¼Œèˆ’å¼ æœŸå‡çŸ­ï¼Œä»è€Œé™ä½å·¦å³å¿ƒå®¤å°„è¡€åˆ†æ•°ï¼Œè¯±å‘å¿ƒå¾‹å¤±å¸¸ï¼›<br/>7ã€é…—é…’ï¼šé•¿æœŸå—œé…’è€…ï¼Œè‚åŠŸå—åˆ°å½±å“ï¼Œä»£è°¢ç´Šä¹±ï¼Œå®¹æ˜“å‡ºç°è„‚è´¨ä»£è°¢å¼‚å¸¸ã€‚ |
| æ€ä¹ˆè®©è‡ªå·±ç²¾åŠ›å……æ²›ï¼Œåˆ—5ç‚¹å»ºè®®                                                                    | 1ã€ä¿è¯ç¡çœ è´¨é‡ï¼šæ¯å¤©æ™šä¸Š7-8å°æ—¶çš„é«˜è´¨é‡ç¡çœ æ˜¯æå‡èº«ä½“å’Œå¤§è„‘æ´»è·ƒåº¦æœ€æœ‰æ•ˆçš„æ–¹æ³•ã€‚<br/>2ã€åˆç†é¥®é£Ÿï¼šå‡è¡¡è¥å…»æ‘„å…¥å¯¹äºç»´æŒäººä½“æ­£å¸¸è¿è½¬è‡³å…³é‡è¦ï¼Œå¤šåƒè”¬èœæ°´æœï¼Œå°‘æ²¹è…»è¾›è¾£åˆºæ¿€æ€§é£Ÿç‰©ã€‚<br/>3ã€é€‚å½“é”»ç‚¼ï¼šåšæŒä¸€å®šå¼ºåº¦çš„é”»ç‚¼å¯ä»¥ä¿ƒè¿›è¡€æ¶²å¾ªç¯ï¼Œå¢åŠ è‚Œè‚‰è€åŠ›ï¼Œæ”¹å–„å¿ƒè‚ºåŠŸèƒ½ç­‰ã€‚<br/>4ã€å­¦ä¹ æ–°çŸ¥è¯†ï¼šä¸æ–­æ¥è§¦æ–°äº‹ç‰©ï¼Œå¼€æ‹“è§†é‡ï¼Œæ€è€ƒé—®é¢˜ï¼Œéƒ½ä¼šä½¿å¾—æˆ‘ä»¬æ›´å…·åˆ›é€ åŠ›ä¸çµæ„Ÿã€‚<br/>5ã€æ”¾æ¾å¿ƒæƒ…ï¼šé€šè¿‡å†¥æƒ³æˆ–è€…ç‘œä¼½æ¥ç¼“è§£å‹åŠ›ï¼Œä¹Ÿå¯ä»¥å¬éŸ³ä¹æˆ–çœ‹ç”µå½±æ¥è°ƒèŠ‚æƒ…ç»ªã€‚                                                                                                                                                                 |
| å†™ä¸ªæ˜¥å¤©çš„è¯—                                                                             | æ˜¥é£å¹æ‹‚ï¼ŒèŠ±å„¿ç»½æ”¾ã€‚<br/>é˜³å…‰æ˜åªšï¼Œé¸Ÿè¯­é¸£å«ã€‚<br/>æ ‘æœ¨æŠ½èŠ½ï¼Œè‰åœ°å˜ç»¿ã€‚<br/>ä¸‡ç‰©å¤è‹ï¼Œç”Ÿæœºå‹ƒå‘ã€‚                                                                                                                                                                                                                                                                                                                                                   |
| å—ææ´²ä¸ºå•¥æ²¡æœ‰åŒ—æç†Š?                                                                        |å—ææ˜¯ä¸–ç•Œä¸Šæœ€å¤§çš„å†°ç›–ï¼Œè¦†ç›–ç€98ï¼…ä»¥ä¸Šçš„åœ°çƒè¡¨é¢ç§¯ã€‚å®ƒä½äºå—çº¬60åº¦è‡³74åº¦ä¹‹é—´ï¼Œç¯ç»•åœ¨æµ·æ´‹ä¸­å¿ƒå‘¨å›´ã€‚ç”±äºå…¶ç‹¬ç‰¹çš„æ°”å€™æ¡ä»¶å’Œç”Ÿæ€ç³»ç»Ÿï¼Œå—æè¢«ç§°ä¸ºâ€œçœŸæ­£çš„è’é‡â€ã€‚å—ææ´²æ‹¥æœ‰ä¸°å¯Œå¤šæ ·çš„åŠ¨æ¤ç‰©èµ„æºï¼Œä½†è¿™é‡Œå¹¶ä¸å­˜åœ¨åŒ—æç†Šã€‚ <br/>é‚£ä¹ˆï¼Œä¸ºä»€ä¹ˆå—ææ´²æ²¡æœ‰åŒ—æç†Šå‘¢ï¼Ÿ<br/>é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦äº†è§£ä¸€ä¸‹ä¸¤è€…æ –æ¯åœ°çš„å·®å¼‚ã€‚åŒ—æç†Šä¸»è¦åˆ†å¸ƒåœ¨åŒ—åŠçƒå¯’å†·çš„é«˜çº¬åº¦åœ°åŒºï¼Œå¦‚åŠ æ‹¿å¤§ã€æ ¼é™µå…°å²›ç­‰åœ°ã€‚è€Œå—ææ´²åˆ™å¤„äºå—åŠçƒï¼Œå±äºæ¸©å¸¦æˆ–å¯’å¸¦æ°”å€™ç±»å‹ã€‚è™½ç„¶å—ææ´²ä¹Ÿæœ‰å¾ˆä½çš„å¹³å‡æ°”æ¸©ï¼ˆ-25â„ƒå·¦å³ï¼‰ï¼Œä½†ä¸åŒ—æç›¸æ¯”è¿˜æ˜¯å¤ªçƒ­äº†ã€‚å› æ­¤ï¼Œå³ä½¿åŒ—æç†Šèƒ½å¤Ÿé€‚åº”æ›´ä¸¥é…·çš„æ°”å€™æ¡ä»¶ï¼Œå®ƒä»¬ä¹Ÿæ— æ³•åœ¨å—ææ‰¾åˆ°åˆé€‚çš„æ –æ¯åœ°ã€‚<br/>å¦å¤–ï¼Œå—ææ´²ç¼ºä¹é™†åœ°å“ºä¹³åŠ¨ç‰©é£Ÿç‰©æ¥æºï¼ŒåŒ…æ‹¬é±¼ç±»ã€é²¸é±¼å’Œä¼é¹…ç­‰ã€‚å°½ç®¡å—ææ´²çš„æ°´åŸŸä¸­ä¹Ÿæœ‰å„ç§é±¼ç±»ï¼Œä½†æ•°é‡è¿œå°‘äºåŒ—æåœˆå†…ã€‚<br/>åŒæ—¶ï¼Œå—ææ´²çš„åœŸè‘—å±…æ°‘â€”â€”ä¼é¹…ç¾¤ä½“ç¹æ®–å­£èŠ‚æœŸé—´ä¼šæ¶ˆè€—æ‰å¤§éƒ¨åˆ†å¯ç”¨çš„é£Ÿç‰©èµ„æºï¼Œå¯¼è‡´å½“åœ°çš„é±¼ç±»æ•°é‡å‡å°‘ç”šè‡³æ¯ç«­ã€‚|

</details>

## ğŸ“š Dataset 
### åŒ»ç–—æ•°æ®é›†

- 240ä¸‡æ¡ä¸­æ–‡åŒ»ç–—æ•°æ®é›†(åŒ…æ‹¬é¢„è®­ç»ƒã€æŒ‡ä»¤å¾®è°ƒå’Œå¥–åŠ±æ•°æ®é›†)ï¼š[shibing624/medical](https://huggingface.co/datasets/shibing624/medical)
- 22ä¸‡æ¡ä¸­æ–‡åŒ»ç–—å¯¹è¯æ•°æ®é›†(åä½—é¡¹ç›®)ï¼š[FreedomIntelligence/HuatuoGPT-sft-data-v1](https://huggingface.co/datasets/FreedomIntelligence/HuatuoGPT-sft-data-v1)

### é€šç”¨æ•°æ®é›†

#### Pretraining datasets
- 16GBä¸­è‹±æ–‡æ— ç›‘ç£ã€å¹³è¡Œè¯­æ–™[Linly-AI/Chinese-pretraining-dataset](https://huggingface.co/datasets/Linly-AI/Chinese-pretraining-dataset)
- 524MBä¸­æ–‡ç»´åŸºç™¾ç§‘è¯­æ–™[wikipedia-cn-20230720-filtered](https://huggingface.co/datasets/pleisto/wikipedia-cn-20230720-filtered)
#### SFT datasets
- 6åƒæ¡å¤šè¯­è¨€ShareGPT GPT4å¤šè½®å¯¹è¯æ•°æ®é›†ï¼š[shibing624/sharegpt_gpt4](https://huggingface.co/datasets/shibing624/sharegpt_gpt4) [æœ¬é¡¹ç›®æ”¯æŒæ ¼å¼]
- 9ä¸‡æ¡è‹±æ–‡ShareGPTå¤šè½®å¯¹è¯æ•°é›†ï¼š[anon8231489123/ShareGPT_Vicuna_unfiltered](https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered) [æœ¬é¡¹ç›®æ”¯æŒæ ¼å¼]
- 50ä¸‡æ¡ä¸­æ–‡ChatGPTæŒ‡ä»¤Belleæ•°æ®é›†ï¼š[BelleGroup/train_0.5M_CN](https://huggingface.co/datasets/BelleGroup/train_0.5M_CN)
- 100ä¸‡æ¡ä¸­æ–‡ChatGPTæŒ‡ä»¤Belleæ•°æ®é›†ï¼š[BelleGroup/train_1M_CN](https://huggingface.co/datasets/BelleGroup/train_1M_CN)
- 5ä¸‡æ¡è‹±æ–‡ChatGPTæŒ‡ä»¤Alpacaæ•°æ®é›†ï¼š[50k English Stanford Alpaca dataset](https://github.com/tatsu-lab/stanford_alpaca#data-release)
- 2ä¸‡æ¡ä¸­æ–‡ChatGPTæŒ‡ä»¤Alpacaæ•°æ®é›†ï¼š[shibing624/alpaca-zh](https://huggingface.co/datasets/shibing624/alpaca-zh)
- 69ä¸‡æ¡ä¸­æ–‡æŒ‡ä»¤Guanacoæ•°æ®é›†(Belle50ä¸‡æ¡+Guanaco19ä¸‡æ¡)ï¼š[Chinese-Vicuna/guanaco_belle_merge_v1.0](https://huggingface.co/datasets/Chinese-Vicuna/guanaco_belle_merge_v1.0)
- 5ä¸‡æ¡è‹±æ–‡ChatGPTå¤šè½®å¯¹è¯æ•°æ®é›†ï¼š[RyokoAI/ShareGPT52K](https://huggingface.co/datasets/RyokoAI/ShareGPT52K)
- 80ä¸‡æ¡ä¸­æ–‡ChatGPTå¤šè½®å¯¹è¯æ•°æ®é›†ï¼š[BelleGroup/multiturn_chat_0.8M](https://huggingface.co/datasets/BelleGroup/multiturn_chat_0.8M)
- 116ä¸‡æ¡ä¸­æ–‡ChatGPTå¤šè½®å¯¹è¯æ•°æ®é›†ï¼š[fnlp/moss-002-sft-data](https://huggingface.co/datasets/fnlp/moss-002-sft-data)
- 3.8ä¸‡æ¡ä¸­æ–‡ShareGPTå¤šè½®å¯¹è¯æ•°æ®é›†ï¼š[FreedomIntelligence/ShareGPT-CN](https://huggingface.co/datasets/FreedomIntelligence/ShareGPT-CN)

#### Reward Model datasets
- åŸç‰ˆçš„oasst1æ•°æ®é›†ï¼š[OpenAssistant/oasst1](https://huggingface.co/datasets/OpenAssistant/oasst1)
- 2ä¸‡æ¡å¤šè¯­è¨€oasst1çš„rewardæ•°æ®é›†ï¼š[tasksource/oasst1_pairwise_rlhf_reward](https://huggingface.co/datasets/tasksource/oasst1_pairwise_rlhf_reward)
- 11ä¸‡æ¡è‹±æ–‡hh-rlhfçš„rewardæ•°æ®é›†ï¼š[Dahoas/full-hh-rlhf](https://huggingface.co/datasets/Dahoas/full-hh-rlhf)
- 9ä¸‡æ¡è‹±æ–‡rewardæ•°æ®é›†(æ¥è‡ªAnthropic's Helpful Harmless dataset)ï¼š[Dahoas/static-hh](https://huggingface.co/datasets/Dahoas/static-hh)
- 7ä¸‡æ¡è‹±æ–‡rewardæ•°æ®é›†ï¼ˆæ¥æºåŒä¸Šï¼‰ï¼š[Dahoas/rm-static](https://huggingface.co/datasets/Dahoas/rm-static)
- 7ä¸‡æ¡ç¹ä½“ä¸­æ–‡çš„rewardæ•°æ®é›†ï¼ˆç¿»è¯‘è‡ªrm-staticï¼‰[liswei/rm-static-m2m100-zh](https://huggingface.co/datasets/liswei/rm-static-m2m100-zh)
- 7ä¸‡æ¡è‹±æ–‡Rewardæ•°æ®é›†ï¼š[yitingxie/rlhf-reward-datasets](https://huggingface.co/datasets/yitingxie/rlhf-reward-datasets)
- 3åƒæ¡ä¸­æ–‡çŸ¥ä¹é—®ç­”åå¥½æ•°æ®é›†ï¼š[liyucheng/zhihu_rlhf_3k](https://huggingface.co/datasets/liyucheng/zhihu_rlhf_3k)

## âœ… Todo

1. [x] add multi-round dialogue data fine-tuning method
2. [x] add reward model fine-tuning
3. [x] add rl fine-tuning
4. [x] add medical reward dataset
5. [x] add llama in8/int4 training
6. [x] add all training and predict demo in colab

## â˜ï¸ Contact

- Issue(å»ºè®®)
  ï¼š[![GitHub issues](https://img.shields.io/github/issues/shibing624/MedicalGPT.svg)](https://github.com/shibing624/MedicalGPT/issues)
- é‚®ä»¶æˆ‘ï¼šxuming: xuming624@qq.com
- å¾®ä¿¡æˆ‘ï¼š åŠ æˆ‘*å¾®ä¿¡å·ï¼šxuming624, å¤‡æ³¨ï¼šå§“å-å…¬å¸å-NLP* è¿›NLPäº¤æµç¾¤ã€‚

<img src="https://github.com/shibing624/MedicalGPT/blob/main/docs/wechat.jpeg" width="200" />

## âš ï¸ å±€é™æ€§ã€ä½¿ç”¨é™åˆ¶ä¸å…è´£å£°æ˜

åŸºäºå½“å‰æ•°æ®å’ŒåŸºç¡€æ¨¡å‹è®­ç»ƒå¾—åˆ°çš„SFTæ¨¡å‹ï¼Œåœ¨æ•ˆæœä¸Šä»å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š

1. åœ¨æ¶‰åŠäº‹å®æ€§çš„æŒ‡ä»¤ä¸Šå¯èƒ½ä¼šäº§ç”Ÿè¿èƒŒäº‹å®çš„é”™è¯¯å›ç­”ã€‚

2. å¯¹äºå…·å¤‡å±å®³æ€§çš„æŒ‡ä»¤æ— æ³•å¾ˆå¥½çš„é‰´åˆ«ï¼Œç”±æ­¤ä¼šäº§ç”Ÿå±å®³æ€§è¨€è®ºã€‚

3. åœ¨ä¸€äº›æ¶‰åŠæ¨ç†ã€ä»£ç ã€å¤šè½®å¯¹è¯ç­‰åœºæ™¯ä¸‹æ¨¡å‹çš„èƒ½åŠ›ä»æœ‰å¾…æé«˜ã€‚

åŸºäºä»¥ä¸Šæ¨¡å‹å±€é™æ€§ï¼Œæˆ‘ä»¬è¦æ±‚å¼€å‘è€…ä»…å°†æˆ‘ä»¬å¼€æºçš„æ¨¡å‹æƒé‡åŠåç»­ç”¨æ­¤é¡¹ç›®ç”Ÿæˆçš„è¡ç”Ÿç‰©ç”¨äºç ”ç©¶ç›®çš„ï¼Œä¸å¾—ç”¨äºå•†ä¸šï¼Œä»¥åŠå…¶ä»–ä¼šå¯¹ç¤¾ä¼šå¸¦æ¥å±å®³çš„ç”¨é€”ã€‚

æœ¬é¡¹ç›®ä»…å¯åº”ç”¨äºç ”ç©¶ç›®çš„ï¼Œé¡¹ç›®å¼€å‘è€…ä¸æ‰¿æ‹…ä»»ä½•å› ä½¿ç”¨æœ¬é¡¹ç›®ï¼ˆåŒ…å«ä½†ä¸é™äºæ•°æ®ã€æ¨¡å‹ã€ä»£ç ç­‰ï¼‰å¯¼è‡´çš„å±å®³æˆ–æŸå¤±ã€‚è¯¦ç»†è¯·å‚è€ƒ[å…è´£å£°æ˜](https://github.com/shibing624/MedicalGPT/blob/main/DISCLAIMER)ã€‚

é¡¹ç›®ä»£ç çš„æˆæƒåè®®ä¸º [The Apache License 2.0](/LICENSE)ï¼Œä»£ç å¯å…è´¹ç”¨åšå•†ä¸šç”¨é€”ï¼Œæ¨¡å‹æƒé‡å’Œæ•°æ®åªèƒ½ç”¨äºç ”ç©¶ç›®çš„ã€‚è¯·åœ¨äº§å“è¯´æ˜ä¸­é™„åŠ MedicalGPTçš„é“¾æ¥å’Œæˆæƒåè®®ã€‚


## ğŸ˜‡ Citation

å¦‚æœä½ åœ¨ç ”ç©¶ä¸­ä½¿ç”¨äº†MedicalGPTï¼Œè¯·æŒ‰å¦‚ä¸‹æ ¼å¼å¼•ç”¨ï¼š

```latex
@misc{MedicalGPT,
  title={MedicalGPT: Training Medical GPT Model},
  author={Ming Xu},
  year={2023},
  howpublished={\url{https://github.com/shibing624/MedicalGPT}},
}
```

## ğŸ˜ Contribute

é¡¹ç›®ä»£ç è¿˜å¾ˆç²—ç³™ï¼Œå¦‚æœå¤§å®¶å¯¹ä»£ç æœ‰æ‰€æ”¹è¿›ï¼Œæ¬¢è¿æäº¤å›æœ¬é¡¹ç›®ï¼Œåœ¨æäº¤ä¹‹å‰ï¼Œæ³¨æ„ä»¥ä¸‹ä¸¤ç‚¹ï¼š

- åœ¨`tests`æ·»åŠ ç›¸åº”çš„å•å…ƒæµ‹è¯•
- ä½¿ç”¨`python -m pytest`æ¥è¿è¡Œæ‰€æœ‰å•å…ƒæµ‹è¯•ï¼Œç¡®ä¿æ‰€æœ‰å•æµ‹éƒ½æ˜¯é€šè¿‡çš„

ä¹‹åå³å¯æäº¤PRã€‚

## ğŸ’• Acknowledgements 

- [tloen/alpaca-lora](https://github.com/tloen/alpaca-lora/blob/main/finetune.py)
- [ymcui/Chinese-LLaMA-Alpaca](https://github.com/ymcui/Chinese-LLaMA-Alpaca)

Thanks for their great work!
