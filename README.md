[**ğŸ‡¨ğŸ‡³ä¸­æ–‡**](./README.md) | [**ğŸŒEnglish**](./README_EN.md) | [**ğŸ“–æ–‡æ¡£/Docs**](https://github.com/ymcui/Chinese-LLaMA-Alpaca/wiki) | [**â“æé—®/Issues**](https://github.com/ymcui/Chinese-LLaMA-Alpaca/issues)

<div align="center">
  <a href="https://github.com/shibing624/MedicalGPT">
    <img src="https://github.com/shibing624/MedicalGPT/blob/main/docs/logo.png" width="120" alt="Logo">
  </a>
</div>

-----------------

# MedicalGPT: Training Medical GPT Model
[![HF Models](https://img.shields.io/badge/Hugging%20Face-shibing624-green)](https://huggingface.co/shibing624)
[![Github Stars](https://img.shields.io/github/stars/shibing624/MedicalGPT?color=yellow)](https://star-history.com/#shibing624/MedicalGPT&Timeline)
[![Contributions welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg)](CONTRIBUTING.md)
[![License Apache 2.0](https://img.shields.io/badge/license-Apache%202.0-blue.svg)](LICENSE)
[![python_version](https://img.shields.io/badge/Python-3.8%2B-green.svg)](requirements.txt)
[![GitHub issues](https://img.shields.io/github/issues/shibing624/MedicalGPT.svg)](https://github.com/shibing624/MedicalGPT/issues)
[![Wechat Group](http://vlog.sfyc.ltd/wechat_everyday/wxgroup_logo.png?imageView2/0/w/60/h/20)](#Contact)

## ğŸ“– Introduction

**MedicalGPT** training medical GPT model with ChatGPT training pipeline, implemantation of Pretraining, 
Supervised Finetuning, Reward Modeling and Reinforcement Learning.

**MedicalGPT** è®­ç»ƒåŒ»ç–—å¤§æ¨¡å‹ï¼Œå®ç°åŒ…æ‹¬äºŒæ¬¡é¢„è®­ç»ƒã€æœ‰ç›‘ç£å¾®è°ƒã€å¥–åŠ±å»ºæ¨¡ã€å¼ºåŒ–å­¦ä¹ è®­ç»ƒã€‚

<img src="https://github.com/shibing624/MedicalGPT/blob/main/docs/GPT_Training.jpg" width="860" />

è®­ç»ƒé¢†åŸŸæ¨¡å‹--åŒ»ç–—æ¨¡å‹ï¼Œåˆ†å››é˜¶æ®µï¼š

- ç¬¬ä¸€é˜¶æ®µï¼šPT(Continue PreTraining)å¢é‡é¢„è®­ç»ƒï¼Œåœ¨æµ·é‡é¢†åŸŸæ–‡æ¡£æ•°æ®ä¸ŠäºŒæ¬¡é¢„è®­ç»ƒLLaMAæ¨¡å‹ï¼Œä»¥æ³¨å…¥é¢†åŸŸçŸ¥è¯†ï¼Œå¦‚æœ‰éœ€è¦å¯ä»¥æ‰©å……é¢†åŸŸè¯è¡¨ï¼Œæ¯”å¦‚åŒ»ç–—é¢†åŸŸè¯è¡¨
- ç¬¬äºŒé˜¶æ®µï¼šSFT(Supervised Fine-tuning)æœ‰ç›‘ç£å¾®è°ƒï¼Œæ„é€ æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†ï¼Œåœ¨é¢„è®­ç»ƒæ¨¡å‹åŸºç¡€ä¸ŠåšæŒ‡ä»¤ç²¾è°ƒï¼Œä»¥å¯¹é½æŒ‡ä»¤æ„å›¾
- ç¬¬ä¸‰é˜¶æ®µï¼šRM(Reward Model)å¥–åŠ±æ¨¡å‹å»ºæ¨¡ï¼Œæ„é€ äººç±»åå¥½æ’åºæ•°æ®é›†ï¼Œè®­ç»ƒå¥–åŠ±æ¨¡å‹ï¼Œç”¨æ¥å¯¹é½äººç±»åå¥½ï¼Œä¸»è¦æ˜¯"HHH"åŸåˆ™ï¼Œå…·ä½“æ˜¯"helpful, honest, harmless"
- ç¬¬å››é˜¶æ®µï¼šRL(Reinforcement Learning)åŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ (RLHF)ï¼Œç”¨å¥–åŠ±æ¨¡å‹æ¥è®­ç»ƒSFTæ¨¡å‹ï¼Œç”Ÿæˆæ¨¡å‹ä½¿ç”¨å¥–åŠ±æˆ–æƒ©ç½šæ¥æ›´æ–°å…¶ç­–ç•¥ï¼Œä»¥ä¾¿ç”Ÿæˆæ›´é«˜è´¨é‡ã€æ›´ç¬¦åˆäººç±»åå¥½çš„æ–‡æœ¬

## â–¶ï¸ Demo

- Hugging Face Demo: doing

æˆ‘ä»¬æä¾›äº†ä¸€ä¸ªç®€æ´çš„åŸºäºgradioçš„äº¤äº’å¼webç•Œé¢ï¼Œå¯åŠ¨æœåŠ¡åï¼Œå¯é€šè¿‡æµè§ˆå™¨è®¿é—®ï¼Œè¾“å…¥é—®é¢˜ï¼Œæ¨¡å‹ä¼šè¿”å›ç­”æ¡ˆã€‚

å¯åŠ¨æœåŠ¡ï¼Œå‘½ä»¤å¦‚ä¸‹ï¼š
```shell
python scripts/gradio_demo.py --base_model path_to_llama_hf_dir --lora_model path_to_lora_dir
```

å‚æ•°è¯´æ˜ï¼š

- `--base_model {base_model}`ï¼šå­˜æ”¾HFæ ¼å¼çš„LLaMAæ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶çš„ç›®å½•ï¼Œä¹Ÿå¯ä½¿ç”¨HF Model Hubæ¨¡å‹è°ƒç”¨åç§°
- `--lora_model {lora_model}`ï¼šLoRAæ–‡ä»¶æ‰€åœ¨ç›®å½•ï¼Œä¹Ÿå¯ä½¿ç”¨HF Model Hubæ¨¡å‹è°ƒç”¨åç§°ã€‚è‹¥loraæƒé‡å·²ç»åˆå¹¶åˆ°é¢„è®­ç»ƒæ¨¡å‹ï¼Œåˆ™åˆ é™¤--lora_modelå‚æ•°
- `--tokenizer_path {tokenizer_path}`ï¼šå­˜æ”¾å¯¹åº”tokenizerçš„ç›®å½•ã€‚è‹¥ä¸æä¾›æ­¤å‚æ•°ï¼Œåˆ™å…¶é»˜è®¤å€¼ä¸--lora_modelç›¸åŒï¼›è‹¥ä¹Ÿæœªæä¾›--lora_modelå‚æ•°ï¼Œåˆ™å…¶é»˜è®¤å€¼ä¸--base_modelç›¸åŒ
- `--use_cpu`: ä»…ä½¿ç”¨CPUè¿›è¡Œæ¨ç†
- `--gpus {gpu_ids}`: æŒ‡å®šä½¿ç”¨çš„GPUè®¾å¤‡ç¼–å·ï¼Œé»˜è®¤ä¸º0ã€‚å¦‚ä½¿ç”¨å¤šå¼ GPUï¼Œä»¥é€—å·åˆ†éš”ï¼Œå¦‚0,1,2


## ğŸš€ Training Pipeline

### Stage 1: Continue Pretraining
ç¬¬ä¸€é˜¶æ®µï¼šPT(Continue PreTraining)å¢é‡é¢„è®­ç»ƒ

åŸºäºllama-7bæ¨¡å‹ï¼Œä½¿ç”¨åŒ»ç–—ç™¾ç§‘ç±»æ•°æ®ç»§ç»­é¢„è®­ç»ƒï¼ŒæœŸæœ›æ³¨å…¥åŒ»ç–—çŸ¥è¯†åˆ°é¢„è®­ç»ƒæ¨¡å‹ï¼Œå¾—åˆ°llama-7b-ptæ¨¡å‹ï¼Œæ­¤æ­¥éª¤å¯é€‰

Continue pretraining of the base llama-7b model to create llama-7b-pt:

```shell
cd scripts
sh run_pt.sh
```

[è®­ç»ƒå‚æ•°è¯´æ˜wiki](https://github.com/shibing624/MedicalGPT/wiki/%E8%AE%AD%E7%BB%83%E7%BB%86%E8%8A%82%E8%AF%B4%E6%98%8E)

### Stage 2: Supervised FineTuning
ç¬¬äºŒé˜¶æ®µï¼šSFT(Supervised Fine-tuning)æœ‰ç›‘ç£å¾®è°ƒ

åŸºäºllama-7b-ptæ¨¡å‹ï¼Œä½¿ç”¨åŒ»ç–—é—®ç­”ç±»æ•°æ®è¿›è¡Œæœ‰ç›‘ç£å¾®è°ƒï¼Œå¾—åˆ°llama-7b-sftæ¨¡å‹

Supervised fine-tuning of the base llama-7b-pt model to create llama-7b-sft

```shell
cd scripts
sh run_sft.sh
```

[è®­ç»ƒå‚æ•°è¯´æ˜wiki](https://github.com/shibing624/MedicalGPT/wiki/%E8%AE%AD%E7%BB%83%E7%BB%86%E8%8A%82%E8%AF%B4%E6%98%8E)

### Stage 3: Reward Modeling
ç¬¬ä¸‰é˜¶æ®µï¼šRM(Reward Model)å¥–åŠ±æ¨¡å‹å»ºæ¨¡

RM(Reward Model)å¥–åŠ±æ¨¡å‹ï¼ŒåŸåˆ™ä¸Šï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥ç”¨äººç±»æ ‡æ³¨æ¥å¯¹æ¨¡å‹åš RLHF å¾®è°ƒã€‚

ç„¶è€Œï¼Œè¿™å°†éœ€è¦æˆ‘ä»¬ç»™äººç±»å‘é€ä¸€äº›æ ·æœ¬ï¼Œåœ¨æ¯è½®ä¼˜åŒ–åè®¡åˆ†ã€‚è¿™æ˜¯è´µä¸”æ…¢çš„ï¼Œå› ä¸ºæ”¶æ•›éœ€è¦çš„è®­ç»ƒæ ·æœ¬é‡å¤§ï¼Œè€Œäººç±»é˜…è¯»å’Œæ ‡æ³¨çš„é€Ÿåº¦æœ‰é™ã€‚
ä¸€ä¸ªæ¯”ç›´æ¥åé¦ˆæ›´å¥½çš„ç­–ç•¥æ˜¯ï¼Œåœ¨è¿›å…¥ RL å¾ªç¯ä¹‹å‰ç”¨äººç±»æ ‡æ³¨é›†æ¥è®­ç»ƒä¸€ä¸ªå¥–åŠ±æ¨¡å‹RMã€‚å¥–åŠ±æ¨¡å‹çš„ç›®çš„æ˜¯æ¨¡æ‹Ÿäººç±»å¯¹æ–‡æœ¬çš„æ‰“åˆ†ã€‚

æ„å»ºå¥–åŠ±æ¨¡å‹çš„æœ€ä½³å®è·µæ˜¯é¢„æµ‹ç»“æœçš„æ’åºï¼Œå³å¯¹æ¯ä¸ª prompt (è¾“å…¥æ–‡æœ¬) å¯¹åº”çš„ä¸¤ä¸ªç»“æœ (yk, yj)ï¼Œæ¨¡å‹é¢„æµ‹äººç±»æ ‡æ³¨çš„æ¯”åˆ†å“ªä¸ªæ›´é«˜ã€‚
RMæ¨¡å‹æ˜¯é€šè¿‡äººå·¥æ ‡æ³¨SFTæ¨¡å‹çš„æ‰“åˆ†ç»“æœæ¥è®­ç»ƒçš„ï¼Œç›®çš„æ˜¯å–ä»£äººå·¥æ‰“åˆ†ï¼Œæœ¬è´¨æ˜¯ä¸ªå›å½’æ¨¡å‹ï¼Œç”¨æ¥å¯¹é½äººç±»åå¥½ï¼Œä¸»è¦æ˜¯"HHH"åŸåˆ™ï¼Œå…·ä½“æ˜¯"helpful, honest, harmless"ã€‚


åŸºäºllama-7b-sftæ¨¡å‹ï¼Œä½¿ç”¨åŒ»ç–—é—®ç­”åå¥½æ•°æ®è®­ç»ƒå¥–åŠ±åå¥½æ¨¡å‹ï¼Œè®­ç»ƒå¾—åˆ°llama-7b-rewardæ¨¡å‹

Reward modeling using dialog pairs from the reward dataset using the llama-7b-sft to create llama-7b-reward:

```shell
cd scripts
sh run_rm.sh
```
[è®­ç»ƒå‚æ•°è¯´æ˜wiki](https://github.com/shibing624/MedicalGPT/wiki/%E8%AE%AD%E7%BB%83%E7%BB%86%E8%8A%82%E8%AF%B4%E6%98%8E)

### Stage 4: Reinforcement Learning
ç¬¬å››é˜¶æ®µï¼šRL(Reinforcement Learning)åŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ (RLHF)

RL(Reinforcement Learning)æ¨¡å‹çš„ç›®çš„æ˜¯æœ€å¤§åŒ–å¥–åŠ±æ¨¡å‹çš„è¾“å‡ºï¼ŒåŸºäºä¸Šé¢æ­¥éª¤ï¼Œæˆ‘ä»¬æœ‰äº†å¾®è°ƒçš„è¯­è¨€æ¨¡å‹(llama-7b-sft)å’Œå¥–åŠ±æ¨¡å‹(llama-7b-reward)ï¼Œ
å¯ä»¥å¼€å§‹æ‰§è¡Œ RL å¾ªç¯äº†ã€‚

è¿™ä¸ªè¿‡ç¨‹å¤§è‡´åˆ†ä¸ºä¸‰æ­¥ï¼š

1. è¾“å…¥promptï¼Œæ¨¡å‹ç”Ÿæˆç­”å¤
2. ç”¨å¥–åŠ±æ¨¡å‹æ¥å¯¹ç­”å¤è¯„åˆ†
3. åŸºäºè¯„åˆ†ï¼Œè¿›è¡Œä¸€è½®ç­–ç•¥ä¼˜åŒ–çš„å¼ºåŒ–å­¦ä¹ (PPO)

<img src=https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/blog/stackllama/trl_loop.png height=400 />


åŸºäºllama-7b-rewardæ¨¡å‹ RL å¾®è°ƒè®­ç»ƒllama-7b-sftæ¨¡å‹ï¼Œå¾—åˆ°llama-7b-rlæ¨¡å‹

Reinforcement Learning fine-tuning of llama-7b-sft with the llama-7b-reward reward model to create llama-7b-rl

```shell
cd scripts
sh run_rl.sh
```
[è®­ç»ƒå‚æ•°è¯´æ˜wiki](https://github.com/shibing624/MedicalGPT/wiki/%E8%AE%AD%E7%BB%83%E7%BB%86%E8%8A%82%E8%AF%B4%E6%98%8E)
## ğŸ”¥ Inference 
è®­ç»ƒå®Œæˆåï¼Œç°åœ¨æˆ‘ä»¬åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹ï¼ŒéªŒè¯æ¨¡å‹ç”Ÿæˆæ–‡æœ¬çš„æ•ˆæœã€‚

```shell
python scripts/inference.py \
    --base_model path_to_llama_hf_dir \
    --lora_model path_to_lora \
    --with_prompt \
    --interactive
```

å‚æ•°è¯´æ˜ï¼š

- `--base_model {base_model}`ï¼šå­˜æ”¾HFæ ¼å¼çš„LLaMAæ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶çš„ç›®å½•
- `--lora_model {lora_model}`ï¼šLoRAè§£å‹åæ–‡ä»¶æ‰€åœ¨ç›®å½•ï¼Œä¹Ÿå¯ä½¿ç”¨HF Model Hubæ¨¡å‹è°ƒç”¨åç§°ã€‚å¦‚æœå·²ç»åˆå¹¶äº†LoRAæƒé‡åˆ°é¢„è®­ç»ƒæ¨¡å‹ï¼Œåˆ™å¯ä»¥ä¸æä¾›æ­¤å‚æ•°
- `--tokenizer_path {tokenizer_path}`ï¼šå­˜æ”¾å¯¹åº”tokenizerçš„ç›®å½•ã€‚è‹¥ä¸æä¾›æ­¤å‚æ•°ï¼Œåˆ™å…¶é»˜è®¤å€¼ä¸--lora_modelç›¸åŒï¼›è‹¥ä¹Ÿæœªæä¾›--lora_modelå‚æ•°ï¼Œåˆ™å…¶é»˜è®¤å€¼ä¸--base_modelç›¸åŒ
- `--with_prompt`ï¼šæ˜¯å¦å°†è¾“å…¥ä¸promptæ¨¡ç‰ˆè¿›è¡Œåˆå¹¶ã€‚å¦‚æœåŠ è½½Alpacaæ¨¡å‹ï¼Œè¯·åŠ¡å¿…å¯ç”¨æ­¤é€‰é¡¹ï¼
- `--interactive`ï¼šä»¥äº¤äº’æ–¹å¼å¯åŠ¨ï¼Œä»¥ä¾¿è¿›è¡Œå¤šæ¬¡å•è½®é—®ç­”
- `--data_file {file_name}`ï¼šéäº¤äº’æ–¹å¼å¯åŠ¨ä¸‹ï¼ŒæŒ‰è¡Œè¯»å–file_nameä¸­çš„çš„å†…å®¹è¿›è¡Œé¢„æµ‹
- `--predictions_file {file_name}`ï¼šéäº¤äº’å¼æ–¹å¼ä¸‹ï¼Œå°†é¢„æµ‹çš„ç»“æœä»¥jsonæ ¼å¼å†™å…¥file_name
- `--use_cpu`: ä»…ä½¿ç”¨CPUè¿›è¡Œæ¨ç†
- `--gpus {gpu_ids}`: æŒ‡å®šä½¿ç”¨çš„GPUè®¾å¤‡ç¼–å·ï¼Œé»˜è®¤ä¸º0ã€‚å¦‚ä½¿ç”¨å¤šå¼ GPUï¼Œä»¥é€—å·åˆ†éš”ï¼Œå¦‚0,1,2




#### Inference Examples

<details>

| Human | Assitant |
| ----- | ------ |
| æ€ä¹ˆè®©è‡ªå·±ç²¾åŠ›å……æ²›ï¼Œåˆ—5ç‚¹å»ºè®® | ä»¥ä¸‹æ˜¯ä¸€äº›å¯ä»¥è®©ä½ ä¿æŒç²¾åŠ›å……æ²›çš„å»ºè®®ï¼š <br/>1. ç¡çœ å……è¶³ã€‚ç¡®ä¿æ¯å¤©æ™šä¸Šå¾—åˆ°å……è¶³çš„ç¡çœ æ—¶é—´ã€‚ <br/>2. å¤šè¿åŠ¨ã€‚è¿›è¡Œé€‚åº¦çš„æœ‰æ°§è¿åŠ¨ï¼Œå¦‚æ…¢è·‘ã€æ¸¸æ³³ç­‰ï¼Œå¯ä»¥å¸®åŠ©ä½ æé«˜èƒ½é‡å’Œè€åŠ›ã€‚<br/>3. åƒå¥åº·é£Ÿå“ã€‚é€‰æ‹©å¯Œå«è›‹ç™½è´¨çš„é£Ÿç‰©ï¼Œå¦‚é¸¡è‚‰ã€é±¼è‚‰å’Œé¸¡è›‹ï¼Œä»¥åŠæ–°é²œçš„æ°´æœå’Œè”¬èœã€‚ <br/>4. å‡å°‘å’–å•¡å› çš„æ‘„å…¥é‡ã€‚å°½é‡é¿å…åœ¨ç™½å¤©å–å«å’–å•¡å› çš„é¥®æ–™æˆ–åƒå«æœ‰å’–å•¡å› çš„é£Ÿç‰©ã€‚ <br/>5. æ”¾æ¾èº«å¿ƒã€‚å°è¯•å†¥æƒ³ã€ç‘œä¼½æˆ–å…¶ä»–å½¢å¼çš„æ”¾æ¾æ´»åŠ¨æ¥å‡è½»å‹åŠ›å’Œç„¦è™‘æ„Ÿã€‚ |

</details>
<br/>


## ğŸ“š Dataset 

- 240ä¸‡æ¡ä¸­æ–‡åŒ»ç–—æ•°æ®é›†(åŒ…æ‹¬é¢„è®­ç»ƒã€æŒ‡ä»¤å¾®è°ƒå’Œå¥–åŠ±æ•°æ®é›†)ï¼š[shibing624/medical](https://huggingface.co/datasets/shibing624/medical)

**é™„ä¸Šä¸€äº›é€šç”¨æ•°æ®é›†å’ŒåŒ»ç–—æ•°æ®é›†çš„é“¾æ¥**

- 50ä¸‡æ¡ä¸­æ–‡ChatGPTæŒ‡ä»¤Belleæ•°æ®é›†ï¼š[BelleGroup/train_0.5M_CN](https://huggingface.co/datasets/BelleGroup/train_0.5M_CN)
- 100ä¸‡æ¡ä¸­æ–‡ChatGPTæŒ‡ä»¤Belleæ•°æ®é›†ï¼š[BelleGroup/train_1M_CN](https://huggingface.co/datasets/BelleGroup/train_1M_CN)
- 5ä¸‡æ¡è‹±æ–‡ChatGPTæŒ‡ä»¤Alpacaæ•°æ®é›†ï¼š[50k English Stanford Alpaca dataset](https://github.com/tatsu-lab/stanford_alpaca#data-release)
- 2ä¸‡æ¡ä¸­æ–‡GPT-4æŒ‡ä»¤Alpacaæ•°æ®é›†ï¼š[shibing624/alpaca-zh](https://huggingface.co/datasets/shibing624/alpaca-zh)
- 69ä¸‡æ¡ä¸­æ–‡æŒ‡ä»¤Guanacoæ•°æ®é›†(Belle50ä¸‡æ¡+Guanaco19ä¸‡æ¡)ï¼š[Chinese-Vicuna/guanaco_belle_merge_v1.0](https://huggingface.co/datasets/Chinese-Vicuna/guanaco_belle_merge_v1.0)
- 22ä¸‡æ¡ä¸­æ–‡åŒ»ç–—å¯¹è¯æ•°æ®é›†(åä½—é¡¹ç›®)ï¼š[FreedomIntelligence/HuatuoGPT-sft-data-v1](https://huggingface.co/datasets/FreedomIntelligence/HuatuoGPT-sft-data-v1)

## âœ… Todo

1. [ ] Added multi-round dialogue data fine-tuning method
2. [x] add reward model fine-tuning
3. [x] add rl fine-tuning
4. [x] add medical reward dataset
5. [x] add llama in8/int4 training
6. [ ] add all training and predict demo in colab

## â˜ï¸ Contact

- Issue(å»ºè®®)
  ï¼š[![GitHub issues](https://img.shields.io/github/issues/shibing624/MedicalGPT.svg)](https://github.com/shibing624/MedicalGPT/issues)
- é‚®ä»¶æˆ‘ï¼šxuming: xuming624@qq.com
- å¾®ä¿¡æˆ‘ï¼š åŠ æˆ‘*å¾®ä¿¡å·ï¼šxuming624, å¤‡æ³¨ï¼šå§“å-å…¬å¸å-NLP* è¿›NLPäº¤æµç¾¤ã€‚

<img src="https://github.com/shibing624/MedicalGPT/blob/main/docs/wechat.jpeg" width="200" />

## âš ï¸ å±€é™æ€§ã€ä½¿ç”¨é™åˆ¶ä¸å…è´£å£°æ˜

åŸºäºå½“å‰æ•°æ®å’ŒåŸºç¡€æ¨¡å‹è®­ç»ƒå¾—åˆ°çš„SFTæ¨¡å‹ï¼Œåœ¨æ•ˆæœä¸Šä»å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š

1. åœ¨æ¶‰åŠäº‹å®æ€§çš„æŒ‡ä»¤ä¸Šå¯èƒ½ä¼šäº§ç”Ÿè¿èƒŒäº‹å®çš„é”™è¯¯å›ç­”ã€‚

2. å¯¹äºå…·å¤‡å±å®³æ€§çš„æŒ‡ä»¤æ— æ³•å¾ˆå¥½çš„é‰´åˆ«ï¼Œç”±æ­¤ä¼šäº§ç”Ÿå±å®³æ€§è¨€è®ºã€‚

3. åœ¨ä¸€äº›æ¶‰åŠæ¨ç†ã€ä»£ç ã€å¤šè½®å¯¹è¯ç­‰åœºæ™¯ä¸‹æ¨¡å‹çš„èƒ½åŠ›ä»æœ‰å¾…æé«˜ã€‚

åŸºäºä»¥ä¸Šæ¨¡å‹å±€é™æ€§ï¼Œæˆ‘ä»¬è¦æ±‚å¼€å‘è€…ä»…å°†æˆ‘ä»¬å¼€æºçš„æ¨¡å‹æƒé‡åŠåç»­ç”¨æ­¤é¡¹ç›®ç”Ÿæˆçš„è¡ç”Ÿç‰©ç”¨äºç ”ç©¶ç›®çš„ï¼Œä¸å¾—ç”¨äºå•†ä¸šï¼Œä»¥åŠå…¶ä»–ä¼šå¯¹ç¤¾ä¼šå¸¦æ¥å±å®³çš„ç”¨é€”ã€‚

æœ¬é¡¹ç›®ä»…å¯åº”ç”¨äºç ”ç©¶ç›®çš„ï¼Œé¡¹ç›®å¼€å‘è€…ä¸æ‰¿æ‹…ä»»ä½•å› ä½¿ç”¨æœ¬é¡¹ç›®ï¼ˆåŒ…å«ä½†ä¸é™äºæ•°æ®ã€æ¨¡å‹ã€ä»£ç ç­‰ï¼‰å¯¼è‡´çš„å±å®³æˆ–æŸå¤±ã€‚è¯¦ç»†è¯·å‚è€ƒ[å…è´£å£°æ˜](https://github.com/shibing624/MedicalGPT/blob/main/DISCLAIMER)ã€‚

é¡¹ç›®ä»£ç çš„æˆæƒåè®®ä¸º [The Apache License 2.0](/LICENSE)ï¼Œä»£ç å¯å…è´¹ç”¨åšå•†ä¸šç”¨é€”ï¼Œæ¨¡å‹æƒé‡å’Œæ•°æ®åªèƒ½ç”¨äºç ”ç©¶ç›®çš„ã€‚è¯·åœ¨äº§å“è¯´æ˜ä¸­é™„åŠ MedicalGPTçš„é“¾æ¥å’Œæˆæƒåè®®ã€‚


## ğŸ˜‡ Citation

å¦‚æœä½ åœ¨ç ”ç©¶ä¸­ä½¿ç”¨äº†MedicalGPTï¼Œè¯·æŒ‰å¦‚ä¸‹æ ¼å¼å¼•ç”¨ï¼š

```latex
@misc{MedicalGPT,
  title={MedicalGPT: Training Medical GPT Model},
  author={Ming Xu},
  year={2023},
  howpublished={\url{https://github.com/shibing624/MedicalGPT}},
}
```

## ğŸ˜ Contribute

é¡¹ç›®ä»£ç è¿˜å¾ˆç²—ç³™ï¼Œå¦‚æœå¤§å®¶å¯¹ä»£ç æœ‰æ‰€æ”¹è¿›ï¼Œæ¬¢è¿æäº¤å›æœ¬é¡¹ç›®ï¼Œåœ¨æäº¤ä¹‹å‰ï¼Œæ³¨æ„ä»¥ä¸‹ä¸¤ç‚¹ï¼š

- åœ¨`tests`æ·»åŠ ç›¸åº”çš„å•å…ƒæµ‹è¯•
- ä½¿ç”¨`python -m pytest`æ¥è¿è¡Œæ‰€æœ‰å•å…ƒæµ‹è¯•ï¼Œç¡®ä¿æ‰€æœ‰å•æµ‹éƒ½æ˜¯é€šè¿‡çš„

ä¹‹åå³å¯æäº¤PRã€‚

## ğŸ’• Acknowledgements 

- [tloen/alpaca-lora](https://github.com/tloen/alpaca-lora/blob/main/finetune.py)
- [ymcui/Chinese-LLaMA-Alpaca](https://github.com/ymcui/Chinese-LLaMA-Alpaca)

Thanks for their great work!
